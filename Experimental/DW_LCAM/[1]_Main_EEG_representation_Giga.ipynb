{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[1]_Main_EEG_representation_Giga.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit ('keras_2': conda)",
      "language": "python",
      "name": "python36964bitkeras2conda59be9c9ec18e4cfd8a6b710b6bd0170c"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UN-GCPDS/python-gcpds.EEG_Tensorflow_models/blob/main/Experimental/DW_LCAM/%5B1%5D_Main_EEG_representation_Giga.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWUE2feMKN6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "426fb2a8-5b6a-4f0b-d665-52ac451fa427"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKXbjSorJ6f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe405aa-22c2-4607-ca82-da98785589a1"
      },
      "source": [
        "# Supporting modules\n",
        "#-------------------------------------------------------------------------------\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import pywt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import warnings\n",
        "import shutil\n",
        "from scipy.signal import butter, lfilter, lfilter_zi, filtfilt\n",
        "from sklearn.base import  BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import StratifiedKFold,train_test_split,ShuffleSplit\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#-------------------------------------------------------------------------------\n",
        "!pip install mne==0.19\n",
        "import mne\n",
        "from mne.decoding import CSP\n",
        "from mne.io import read_raw_gdf\n",
        "#-------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne==0.19\n",
            "  Downloading mne-0.19.0-py3-none-any.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mne==0.19) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from mne==0.19) (1.19.5)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAmdfwyKJ6f7"
      },
      "source": [
        "# Definitions-------------------------------------------------------------------\n",
        "def leer_GIGA_data(path_filename,ch,vt,sbj_id):\n",
        "    #--- info ------------------------------------------------------------------\n",
        "    # 2  ---> sample rate \n",
        "    # 7  ---> imaginary_left \n",
        "    # 8  ---> imaginary_right \n",
        "    # 11 ---> imaginary_event \n",
        "    # 14 ---> bad_trials \n",
        "    # class1: left \n",
        "    # class2: right\n",
        "    #---------------------------------------------------------------------------\n",
        "    raw     = sio.loadmat(path_filename)\n",
        "    eeg_raw = raw['eeg']\n",
        "    sfreq   = np.float(eeg_raw[0][0][2])\n",
        "    id_MI   = np.where(eeg_raw[0][0][11]==1)\n",
        "    id_MI   = id_MI[1]\n",
        "    raw_c1  = []\n",
        "    raw_c2  = []\n",
        "    y_c1    = []\n",
        "    y_c2    = []\n",
        "    for i in range(len(id_MI)):\n",
        "        l_thr = id_MI[i]-(sfreq*2-1) \n",
        "        h_thr = id_MI[i]+(sfreq*5)\n",
        "        tmp_c1 = eeg_raw[0][0][7][ch,np.int(l_thr):np.int(h_thr)]\n",
        "        tmp_c2 = eeg_raw[0][0][8][ch,np.int(l_thr):np.int(h_thr)]\n",
        "        raw_c1.append(tmp_c1[:,np.int(vt[0]*sfreq):np.int(vt[1]*sfreq)])\n",
        "        raw_c2.append(tmp_c2[:,np.int(vt[0]*sfreq):np.int(vt[1]*sfreq)])\n",
        "        y_c1.append(1.0)\n",
        "        y_c2.append(2.0)    \n",
        "    # remove bad trials---------------------------------------------------------\n",
        "    id_bad_tr_voltage_c1 = eeg_raw[0][0][14][0][0][0][0][0]\n",
        "    id_bad_tr_voltage_c2 = eeg_raw[0][0][14][0][0][0][0][1]   \n",
        "    id_bad_tr_mi_c1      = eeg_raw[0][0][14][0][0][1][0][0]\n",
        "    id_bad_tr_mi_c2      = eeg_raw[0][0][14][0][0][1][0][1]\n",
        "    ref_axis_c1          = 1\n",
        "    ref_axis_c2          = 1    \n",
        "    if id_bad_tr_mi_c1.shape[0]>id_bad_tr_mi_c1.shape[1]:\n",
        "        id_bad_tr_mi_c1 = id_bad_tr_mi_c1.T\n",
        "    if id_bad_tr_mi_c2.shape[0]>id_bad_tr_mi_c2.shape[1]:\n",
        "        id_bad_tr_mi_c2 = id_bad_tr_mi_c2.T\n",
        "    if id_bad_tr_voltage_c1.shape[1] == 0:\n",
        "        id_bad_tr_voltage_c1 = np.reshape(id_bad_tr_voltage_c1, (id_bad_tr_voltage_c1.shape[0], id_bad_tr_mi_c1.shape[1]))\n",
        "    if id_bad_tr_voltage_c2.shape[1] == 0:\n",
        "        id_bad_tr_voltage_c2 = np.reshape(id_bad_tr_voltage_c2, (id_bad_tr_voltage_c2.shape[0], id_bad_tr_mi_c2.shape[1])) \n",
        "    if (id_bad_tr_voltage_c1.shape[1] > id_bad_tr_mi_c1.shape[1]):\n",
        "        if id_bad_tr_mi_c1.shape[0] == 0:\n",
        "            id_bad_tr_mi_c1 = np.reshape(id_bad_tr_mi_c1, (id_bad_tr_mi_c1.shape[0],id_bad_tr_voltage_c1.shape[1]))\n",
        "            ref_axis_c1     = 0\n",
        "    if (id_bad_tr_voltage_c2.shape[1] > id_bad_tr_mi_c2.shape[1]):\n",
        "        if id_bad_tr_mi_c2.shape[0] == 0:\n",
        "            id_bad_tr_mi_c2 = np.reshape(id_bad_tr_mi_c2, (id_bad_tr_mi_c2.shape[0],id_bad_tr_voltage_c2.shape[1]))\n",
        "            ref_axis_c2     = 0\n",
        "    if (id_bad_tr_mi_c1.shape[0] > id_bad_tr_voltage_c1.shape[0]):\n",
        "        ref_axis_c1 = 0\n",
        "    if (id_bad_tr_mi_c2.shape[0] > id_bad_tr_voltage_c2.shape[0]):\n",
        "        ref_axis_c2 = 0\n",
        "    if (id_bad_tr_voltage_c1.shape[0] > id_bad_tr_mi_c1.shape[0]):\n",
        "        ref_axis_c1 = 0\n",
        "    if (id_bad_tr_voltage_c2.shape[0] > id_bad_tr_mi_c2.shape[0]):\n",
        "        ref_axis_c2 = 0    \n",
        "    id_bad_tr_c1 = np.concatenate((id_bad_tr_voltage_c1,id_bad_tr_mi_c1),axis=ref_axis_c1)\n",
        "    id_bad_tr_c1 = id_bad_tr_c1.ravel()-1\n",
        "    for ele in sorted(id_bad_tr_c1, reverse = True):  \n",
        "        del raw_c1[ele]\n",
        "        del y_c1[ele]\n",
        "    id_bad_tr_c2 = np.concatenate((id_bad_tr_voltage_c2,id_bad_tr_mi_c2),axis=ref_axis_c2)\n",
        "    id_bad_tr_c2= id_bad_tr_c2.ravel()-1\n",
        "    for ele in sorted(id_bad_tr_c2, reverse = True):  \n",
        "        del raw_c2[ele]\n",
        "        del y_c2[ele]     \n",
        "    Xraw = np.array(raw_c1 + raw_c2)\n",
        "    y    = np.array(y_c1 + y_c2)  \n",
        "    return Xraw, y, sfreq\n",
        "#-------------------------------------------------------------------------------\n",
        "def bank_filter_epochsEEG(Xraw, fs, f_frec):\n",
        "    nf,ff             = f_frec.shape\n",
        "    epochs,channels,T = Xraw.shape\n",
        "    Xraw_f            = np.zeros((epochs,channels,T,nf))\n",
        "    for f in range(nf):\n",
        "        lfc = f_frec[f,0]\n",
        "        hfc = f_frec[f,1]\n",
        "        b,a = butter_bandpass(lfc, hfc, fs)\n",
        "        zi  = lfilter_zi(b, a)\n",
        "        for n in range(epochs):\n",
        "            for c in range(channels):\n",
        "                zi              = lfilter_zi(b, a)\n",
        "                Xraw_f[n,c,:,f] = lfilter(b, a, Xraw[n,c,:],zi = zi*Xraw[n,c,0])[0]\n",
        "    return Xraw_f\n",
        "#-------------------------------------------------------------------------------\n",
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    nyq  = 0.5 * fs\n",
        "    low  = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "#-------------------------------------------------------------------------------\n",
        "def calculo_cwt(x,fs):\n",
        "    wname     = 'cmor'\n",
        "    delta     = 1/fs\n",
        "    coef,freq = pywt.cwt(x.T,np.arange(1,32),wname,delta)\n",
        "    return coef, freq\n",
        "#-------------------------------------------------------------------------------\n",
        "def cwt_feat_extraction(X,fs,freq_ref):\n",
        "    X_cwt = np.zeros((X.shape[0],X.shape[1],2))\n",
        "    for tr in range(X.shape[0]):#loop across trials\n",
        "        for ch in range(X.shape[1]):#loop across channels\n",
        "            coef, freq = calculo_cwt(np.squeeze(X[tr,ch,:,0]),fs)\n",
        "            coef       = np.abs(coef)\n",
        "            fb_valavg  = []\n",
        "            for fb in range(freq_ref.shape[0]):#loop across filter bands\n",
        "                coef_mat           = coef[np.where((freq > freq_ref[fb,0]) & (freq <freq_ref[fb,1])),:]  \n",
        "                coef_mat           = np.squeeze(coef_mat[0,:,:])\n",
        "                X_cwt[tr,ch,fb]    = np.mean(coef_mat.flatten()) \n",
        "    return X_cwt\n",
        "#-------------------------------------------------------------------------------\n",
        "from sklearn.base import  BaseEstimator, TransformerMixin\n",
        "class CSP_epochs_filter_extractor(TransformerMixin,BaseEstimator):\n",
        "    def __init__(self, fs,f_frec=[4,30], ncomp=4,reg='empirical'):\n",
        "        self.reg = reg\n",
        "        self.fs = fs\n",
        "        self.f_frec = f_frec\n",
        "        self.ncomp = ncomp\n",
        "        \n",
        "    def _averagingEEG(self,X):      \n",
        "        epochs,channels,T = X.shape\n",
        "        Xc = np.zeros((epochs,channels,T))\n",
        "        for i in range(epochs):\n",
        "            Xc[i,:,:] = X[i,:,:] - np.mean(X[i,:,:])\n",
        "        return Xc    \n",
        "        \n",
        "    def _bank_filter_epochsEEG(self,X):\n",
        "        nf,ff = self.f_frec.shape\n",
        "        epochs,channels,T = X.shape\n",
        "        X_f = np.zeros((epochs,channels,T,nf))\n",
        "        for f in range(nf):\n",
        "            lfc = self.f_frec[f,0]\n",
        "            hfc = self.f_frec[f,1]\n",
        "            b,a = butter_bandpass(lfc, hfc, self.fs)\n",
        "            X_f[:,:,:,f] = filtfilt(b,a,X,axis=2)\n",
        "        return X_f    \n",
        "\n",
        "    def _CSP_epochsEEG(self,Xraw, y,*_):\n",
        "        ncomp = self.ncomp\n",
        "        mne.set_log_level('WARNING')\n",
        "        epochs,channels,T,nf = Xraw.shape\n",
        "        Xcsp = np.zeros((epochs,self.ncomp,nf))\n",
        "        self.filters  =np.zeros((self.ncomp,channels,nf))\n",
        "        csp_l = []\n",
        "        for f in range(nf):\n",
        "            csp_l+= [CSP(n_components=ncomp, reg=self.reg, log=False,transform_into='average_power').fit(Xraw[:,:,:,f],y)]\n",
        "            Xcsp[:,:,f] = csp_l[f].transform(Xraw[:,:,:,f])\n",
        "            self.filters[:,:,f] = csp_l[f].filters_[:self.ncomp]\n",
        "        return csp_l, Xcsp\n",
        "\n",
        "    def fit(self,Xraw,y, *_):\n",
        "        Xraw = self._averagingEEG(Xraw)\n",
        "        Xraw_f = self._bank_filter_epochsEEG(Xraw)\n",
        "        self.csp_l, self.Xcsp = self._CSP_epochsEEG(Xraw_f, y)\n",
        "        return self    \n",
        "   \n",
        "    def transform(self, Xraw, *_):\n",
        "        Xraw = self._averagingEEG(Xraw)\n",
        "        Xraw_f = self._bank_filter_epochsEEG(Xraw)\n",
        "        epochs,channels,T,nf = Xraw_f.shape\n",
        "        ncomp = self.ncomp    \n",
        "        result = np.zeros((epochs,ncomp,nf))   \n",
        "        for f in range(nf):\n",
        "            result[:,:,f] =  self.csp_l[f].transform(Xraw_f[:,:,:,f])    \n",
        "        return result \n",
        "#-------------------------------------------------------------------------------\n",
        "def csp_feat_extraction(Xtrain,ytrain,Xtest,fs,f_frec): \n",
        "    # Y = W.T * X\n",
        "    # A*Y = X ---- A= pinv(W.T)\n",
        "    XT_train = np.zeros((Xtrain.shape[0],Xtrain.shape[1],2))\n",
        "    XT_test  = np.zeros((Xtest.shape[0],Xtest.shape[1],2))\n",
        "    ncomp    = 6# Biclass (4-6) -- Multiclass (8-12) \n",
        "    csp_c    = CSP_epochs_filter_extractor(fs=fs,f_frec=f_frec, ncomp=ncomp)\n",
        "    XT       = csp_c.fit_transform(Xtrain,ytrain)\n",
        "    Filt_    = csp_c.filters\n",
        "    # train/test\n",
        "    for tr in range(Xtrain.shape[0]):#loop across train trials\n",
        "        for fb in range(len(f_frec)):#loop across filter bands\n",
        "            Xpr_tr = []\n",
        "            Xpr_tr = np.dot(Filt_[:,:,fb],Xtrain[tr,:,:])\n",
        "            Xfr_tr = []\n",
        "            Xfr_tr = np.dot(np.linalg.pinv(Filt_[:,:,fb]),Xpr_tr) \n",
        "            XT_train[tr,:,fb] = np.mean(np.abs(Xfr_tr),axis=1)\n",
        "       \n",
        "    for tr in range(Xtest.shape[0]):#loop across test trials\n",
        "        for fb in range(len(f_frec)):#loop across filter bands\n",
        "            Xpr_ts = []\n",
        "            Xpr_ts = np.dot(Filt_[:,:,fb],Xtest[tr,:,:])\n",
        "            Xfr_ts = []\n",
        "            Xfr_ts = np.dot(np.linalg.pinv(Filt_[:,:,fb]),Xpr_ts)\n",
        "            XT_test[tr,:,fb] = np.mean(np.abs(Xfr_ts),axis=1)\n",
        "\n",
        "    return XT_train, XT_test\n",
        "#-------------------------------------------------------------------------------\n",
        "def topomap_generation(types,time_inf,time_sup,id_sbj,info):\n",
        "    cmap = 'gray'\n",
        "    newX = 40\n",
        "    newY = 40\n",
        "    for itm in range(len(types)): #len(types)\n",
        "        #-----------------------------------------------------------------------\n",
        "        path = '/content/drive/MyDrive/Colab Notebooks/GradCam_Paper/GigaData/data/X_'+types[itm]+'_sbj_'+str(id_sbj)+'_Tw_'+str(time_inf)+'s_'+str(time_sup)+'s.pickle'  \n",
        "        with open(path, 'rb') as f:\n",
        "            XT_train, XT_test, y_train, y_test = pickle.load(f)\n",
        "        #-----------------------------------------------------------------------    \n",
        "        try:\n",
        "            os.mkdir('figures/'+str(time_inf)+'s-'+str(time_sup)+'s/'+types[itm])\n",
        "        except OSError:\n",
        "            print('Folder exists!')\n",
        "        #-----------------------------------------------------------------------    \n",
        "        # train \n",
        "        X = XT_train.copy()\n",
        "        #-----------------------------------------------------------------------\n",
        "        try:\n",
        "            os.mkdir('figures/'+str(time_inf)+'s-'+str(time_sup)+'s/'+types[itm]+'/train')\n",
        "        except OSError:\n",
        "            print('Folder exists!')\n",
        "        #-----------------------------------------------------------------------\n",
        "        X_train_reshape = np.zeros((X.shape[0],X.shape[2],int(newX),int(newY)))\n",
        "        #-----------------------------------------------------------------------\n",
        "        fig_mu  = plt.figure(figsize=(10,10))\n",
        "        for tr in range(X.shape[0]):\n",
        "            fig_mu.clear()\n",
        "            image_mu  = []\n",
        "            img_mu    = []\n",
        "            rho_mu    = []\n",
        "            rho_mu    = (X[tr,:,0]-np.min(X[tr,:,0]))/(np.max(X[tr,:,0])-np.min(X[tr,:,0]))\n",
        "            mne.viz.plot_topomap(rho_mu, info, sensors=False, show=False, cmap=cmap, contours=0)\n",
        "            path_mu   = 'figures/'+str(time_inf)+'s-'+str(time_sup)+'s/'+types[itm]+'/train/sbj_'+str(id_sbj)+'_tr_'+str(tr+1)+'_fb_mu.png'\n",
        "            fig_mu.savefig(fname=path_mu,dpi=40,format='png',facecolor='w')\n",
        "            image_mu  = cv2.imread(path_mu,0)\n",
        "            img_mu    = cv2.resize(image_mu,(int(newX),int(newY)))\n",
        "            X_train_reshape[tr,0,:,:] = img_mu\n",
        "        #-----------------------------------------------------------------------\n",
        "        fig_beta = plt.figure(figsize=(10,10))\n",
        "        for tr in range(X.shape[0]):# \n",
        "            fig_beta.clear()\n",
        "            image_beta = []\n",
        "            img_beta   = []\n",
        "            rho_beta   = []\n",
        "            rho_beta   = (X[tr,:,1]-np.min(X[tr,:,1]))/(np.max(X[tr,:,1])-np.min(X[tr,:,1]))\n",
        "            mne.viz.plot_topomap(rho_beta, info, sensors=False, show=False, cmap=cmap, contours=0)\n",
        "            path_beta  = 'figures/'+str(time_inf)+'s-'+str(time_sup)+'s/'+types[itm]+'/train/sbj_'+str(id_sbj)+'_tr_'+str(tr+1)+'_fb_beta.png'\n",
        "            fig_beta.savefig(fname=path_beta,dpi=40,format='png',facecolor='w')\n",
        "            image_beta = cv2.imread(path_beta,0)\n",
        "            img_beta   = cv2.resize(image_beta,(int(newX),int(newY)))\n",
        "            X_train_reshape[tr,1,:,:] = img_beta\n",
        "        #-----------------------------------------------------------------------        \n",
        "        X = X_train_reshape.copy()\n",
        "        #-----------------------------------------------------------------------\n",
        "        # test\n",
        "        X1 = XT_test.copy()\n",
        "        #-----------------------------------------------------------------------\n",
        "        try:\n",
        "            os.mkdir('figures/'+str(time_inf)+'s-'+str(time_sup)+'s/'+types[itm]+'/test')\n",
        "        except OSError:\n",
        "            print('Folder exists!')\n",
        "        #-----------------------------------------------------------------------        \n",
        "        X_test_reshape = np.zeros((X1.shape[0],X1.shape[2],int(newX),int(newY)))\n",
        "        #-----------------------------------------------------------------------            \n",
        "        fig_mu  = plt.figure(figsize=(10,10))\n",
        "        for tr in range(X1.shape[0]):\n",
        "            fig_mu.clear()\n",
        "            image_mu = []\n",
        "            img_mu   = []\n",
        "            rho_mu   = []\n",
        "            rho_mu   = (X1[tr,:,0]-np.min(X1[tr,:,0]))/(np.max(X1[tr,:,0])-np.min(X1[tr,:,0]))\n",
        "            mne.viz.plot_topomap(rho_mu, info, sensors=False, show=False, cmap=cmap, contours=0)\n",
        "            path_mu  = 'figures/'+str(time_inf)+'s-'+str(time_sup)+'s/'+types[itm]+'/test/sbj_'+str(id_sbj)+'_tr_'+str(tr+1)+'_fb_mu.png'\n",
        "            fig_mu.savefig(fname=path_mu,dpi=40,format='png',facecolor='w')\n",
        "            image_mu = cv2.imread(path_mu,0)\n",
        "            img_mu   = cv2.resize(image_mu,(int(newX),int(newY)))\n",
        "            X_test_reshape[tr,0,:,:] = img_mu\n",
        "        #-----------------------------------------------------------------------       \n",
        "        fig_beta = plt.figure(figsize=(10,10))\n",
        "        for tr in range(X1.shape[0]):\n",
        "            fig_beta.clear()\n",
        "            image_beta = []\n",
        "            img_beta   = []\n",
        "            rho_beta   = []\n",
        "            rho_beta   = (X1[tr,:,1]-np.min(X1[tr,:,1]))/(np.max(X1[tr,:,1])-np.min(X1[tr,:,1]))\n",
        "            mne.viz.plot_topomap(rho_beta, info, sensors=False, show=False, cmap=cmap, contours=0)\n",
        "            path_beta  = 'figures/'+str(time_inf)+'s-'+str(time_sup)+'s/'+types[itm]+'/test/sbj_'+str(id_sbj)+'_tr_'+str(tr+1)+'_fb_beta.png'\n",
        "            fig_beta.savefig(fname=path_beta,dpi=40,format='png',facecolor='w')\n",
        "            image_beta = cv2.imread(path_beta,0)\n",
        "            img_beta   = cv2.resize(image_beta,(int(newX),int(newY)))\n",
        "            X_test_reshape[tr,1,:,:] = img_beta\n",
        "        #-----------------------------------------------------------------------  \n",
        "        X1 = X_test_reshape.copy()        \n",
        "        #-----------------------------------------------------------------------\n",
        "        Xtr = X\n",
        "        Xts = X1\n",
        "        with open('/content/drive/MyDrive/Colab Notebooks/GradCam_Paper/GigaData/data/CWT_CSP_data_mubeta_8_30_Tw_'+str(time_inf)+'s_'+str(time_sup)+'s_subject'+str(id_sbj)+'_'+types[itm]+'_resized_10.pickle', 'wb') as f:\n",
        "            pickle.dump([Xtr, Xts, y_train, y_test], f)\n",
        "        #-----------------------------------------------------------------------\n",
        "#-------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYwzOWMfJ6gE"
      },
      "source": [
        "### CWT and CSP feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB4Ggr3sJ6gG",
        "scrolled": true
      },
      "source": [
        ",# Experiment information--------------------------------------------------------\n",
        "th       = np.array([[0.5, 2.5],[1.5, 3.5],[2.5, 4.5],[3.5, 5.5],[4.5, 6.5]])\n",
        "th_name  = np.array([[-1.5, 0.5],[-0.5, 1.5],[0.5, 2.5],[1.5, 3.5],[2.5, 4.5]])\n",
        "freq_ref = np.array([[8,12],[12,30]])\n",
        "Nsbj     = [1]\n",
        "#-------------------------------------------------------------------------------\n",
        "for sbj in range(len(Nsbj)):#loop across subjects\n",
        "    for i in range(th_name.shape[0]):#loop across time windows #\n",
        "        #-----------------------------------------------------------------------\n",
        "        print('Subject - '+str(Nsbj[sbj])+' - Time window '+str(i+1)+' of '+str(th_name.shape[0]))\n",
        "        #-----------------------------------------------------------------------\n",
        "        # load EEG signals------------------------------------------------------\n",
        "        name           = '/content/drive/MyDrive/Universidad-2020/CNN_GIGA/GIGAdata/s' + str(Nsbj[sbj])\n",
        "        filename_train = name+'.mat'\n",
        "        ch             = np.arange(0,64)\n",
        "        vt             = [th[i,0],th[i,1]]\n",
        "        Xraw,y,sfreq   = leer_GIGA_data(filename_train,ch,vt,Nsbj[sbj])\n",
        "        fs             = sfreq\n",
        "\n",
        "        #-----------------------------------------------------------------------\n",
        "        # Filtering-------------------------------------------------------------\n",
        "        f_frec    = np.transpose(np.array([[8],[30]]))\n",
        "        Xraw_filt = bank_filter_epochsEEG(Xraw, fs, f_frec)\n",
        "        #-----------------------------------------------------------------------  \n",
        "        # Split in train/test subsets-------------------------------------------\n",
        "        rs = ShuffleSplit(n_splits=1, train_size=0.9, test_size=0.1, random_state=0)\n",
        "        for train_index, test_index in rs.split(y):\n",
        "            X_train, y_train = Xraw_filt[train_index], y[train_index]\n",
        "            X_test,  y_test  = Xraw_filt[test_index],  y[test_index]\n",
        "        #-----------------------------------------------------------------------\n",
        "        if i==0:\n",
        "            with open('/content/drive/MyDrive/Colab Notebooks/GradCam_Paper/GigaData/data/idxs_train_test_'+str(Nsbj[sbj])+'.pickle', 'wb') as f:\n",
        "                pickle.dump([train_index, test_index], f)\n",
        "        #-----------------------------------------------------------------------\n",
        "        # Compute CWT feature extraction----------------------------------------\n",
        "        X_cwt_train = cwt_feat_extraction(X_train,fs,freq_ref)\n",
        "        X_cwt_test  = cwt_feat_extraction(X_test,fs,freq_ref)\n",
        "        #-----------------------------------------------------------------------\n",
        "        # Compute CSP feature extraction----------------------------------------\n",
        "        X_csp_train,X_csp_test = csp_feat_extraction(np.squeeze(X_train),y_train,np.squeeze(X_test),fs,freq_ref)\n",
        "        #-----------------------------------------------------------------------\n",
        "        # Save extracted features-----------------------------------------------\n",
        "        with open('/content/drive/MyDrive/Colab Notebooks/GradCam_Paper/GigaData/data/X_cwt_sbj_'+str(Nsbj[sbj])+'_Tw_'+str(th_name[i,0])+'s_'+str(th_name[i,1])+'s.pickle', 'wb') as f:\n",
        "            pickle.dump([X_cwt_train, X_cwt_test, y_train, y_test], f)\n",
        "        with open('/content/drive/MyDrive/Colab Notebooks/GradCam_Paper/GigaData/data/X_csp_sbj_'+str(Nsbj[sbj])+'_Tw_'+str(th_name[i,0])+'s_'+str(th_name[i,1])+'s.pickle', 'wb') as f:\n",
        "            pickle.dump([X_csp_train, X_csp_test, y_train, y_test], f)\n",
        "        #-----------------------------------------------------------------------\n",
        "print('Feature Extraction Done!!!\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLCWkBZuJ6gI"
      },
      "source": [
        "### Topographic map montage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9HZiWklJ6gJ"
      },
      "source": [
        "# set EEG montage using standard 10-20 system-----------------------------------\n",
        "channels_names = ['FP1','AF7','AF3','F1','F3','F5','F7','FT7','FC5','FC3','FC1','C1',\n",
        "           'C3','C5','T7','TP7','CP5','CP3','CP1','P1','P3','P5','P7','P9','PO7',\n",
        "           'PO3','O1','Iz','Oz','POz','Pz','CPz','FPz','FP2','AF8','AF4','AFz',\n",
        "           'Fz','F2','F4','F6','F8','FT8','FC6','FC4','FC2','FCz','Cz','C2','C4',\n",
        "           'C6','T8','TP8','CP6','CP4','CP2','P2','P4','P6','P8','P10','PO8',\n",
        "           'PO4','O2']\n",
        "montage = mne.channels.read_montage('standard_1020', channels_names)\n",
        "info = mne.create_info(channels_names, sfreq=512, ch_types=\"eeg\",\n",
        "                         montage=montage)\n",
        "f,ax = plt.subplots(1,1,figsize=(3,3))\n",
        "mne.viz.plot_sensors(info, show_names=True,axes=ax)\n",
        "#-------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lm3bQWmJ6gK"
      },
      "source": [
        "### Topoplot generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8gK-YnRJ6gK",
        "scrolled": true
      },
      "source": [
        "# Load feat data----------------------------------------------------------------\n",
        "th_name  = np.array([[-1.5, 0.5],[-0.5, 1.5],[0.5, 2.5],[1.5, 3.5],[2.5, 4.5]])\n",
        "types    = ['cwt','csp']\n",
        "Nsbj     = [30]\n",
        "#-------------------------------------------------------------------------------\n",
        "for sbj in range(len(Nsbj)):#loop across subjects\n",
        "    try:\n",
        "        os.mkdir('figures')\n",
        "    except OSError:\n",
        "        print('Folder exists!')\n",
        "    for i in range(th_name.shape[0]):#loop across time windows\n",
        "        print('Subject - '+str(Nsbj[sbj])+' - Time window '+str(i+1)+' of '+str(th_name.shape[0]))\n",
        "        try:\n",
        "            os.mkdir('figures/'+str(th_name[i,0])+'s-'+str(th_name[i,1])+'s')\n",
        "        except OSError:\n",
        "            print('Folder exists!')    \n",
        "        topomap_generation(types,th_name[i,0],th_name[i,1],Nsbj[sbj],info)\n",
        "    shutil.rmtree('figures', ignore_errors=True)\n",
        "print('Topoplot generation Done!!!\\n')\n",
        "#-------------------------------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}