{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UN-GCPDS/python-gcpds.EEG_Tensorflow_models/blob/main/Examples/BCI2a/shallowconvnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLD2zi6MxgIf"
      },
      "source": [
        "# BCI2a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-26T17:12:50.456171Z",
          "iopub.status.busy": "2021-09-26T17:12:50.454128Z",
          "iopub.status.idle": "2021-09-26T17:13:06.014392Z",
          "shell.execute_reply": "2021-09-26T17:13:06.013579Z",
          "shell.execute_reply.started": "2021-09-26T17:12:50.456088Z"
        },
        "id": "gb0esQltb-hG",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git\n",
            "  Cloning https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git to /tmp/pip-req-build-ihn6ptif\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git /tmp/pip-req-build-ihn6ptif\n",
            "  Resolved https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git to commit 0d7d468014ceb895c07e69507acbeb6e3924d8a3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting braindecode@ git+https://github.com/braindecode/braindecode\n",
            "  Cloning https://github.com/braindecode/braindecode to /tmp/pip-install-e1g3ovqk/braindecode_66462347214840b1b054e0233794b05d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/braindecode/braindecode /tmp/pip-install-e1g3ovqk/braindecode_66462347214840b1b054e0233794b05d\n",
            "  Resolved https://github.com/braindecode/braindecode to commit 5b4d8daee842c72fbd463b9d4528957fcd32f7be\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting moabb@ git+https://github.com/UN-GCPDS/moabb.git\n",
            "  Cloning https://github.com/UN-GCPDS/moabb.git to /tmp/pip-install-e1g3ovqk/moabb_08a2a63e65e54a77a23c353c65acd7b4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/UN-GCPDS/moabb.git /tmp/pip-install-e1g3ovqk/moabb_08a2a63e65e54a77a23c353c65acd7b4\n",
            "  Resolved https://github.com/UN-GCPDS/moabb.git to commit 57e31a78ab21cb27aad4182d76133303ed574ce9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: mne>=0.23.3 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from EEG-Tensorflow-models==0.1) (0.24.1)\n",
            "Requirement already satisfied: tensorflow-addons in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from EEG-Tensorflow-models==0.1) (0.16.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from mne>=0.23.3->EEG-Tensorflow-models==0.1) (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from mne>=0.23.3->EEG-Tensorflow-models==0.1) (1.22.2)\n",
            "Requirement already satisfied: pandas in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (3.5.1)\n",
            "Requirement already satisfied: h5py in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (3.6.0)\n",
            "Requirement already satisfied: skorch in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (0.11.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from tensorflow-addons->EEG-Tensorflow-models==0.1) (2.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from matplotlib->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (21.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from matplotlib->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (4.29.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from matplotlib->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from matplotlib->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (9.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from matplotlib->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from matplotlib->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from matplotlib->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from pandas->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (2021.3)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from skorch->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (1.0.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from skorch->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from skorch->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (4.63.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from scikit-learn>=0.19.1->skorch->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/daniel/anaconda3/envs/gcpds/lib/python3.8/site-packages (from scikit-learn>=0.19.1->skorch->braindecode@ git+https://github.com/braindecode/braindecode->EEG-Tensorflow-models==0.1) (1.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U git+https://github.com/UN-GCPDS/python-gcpds.EEG_Tensorflow_models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-26T17:13:06.016428Z",
          "iopub.status.busy": "2021-09-26T17:13:06.016145Z",
          "iopub.status.idle": "2021-09-26T17:13:16.770073Z",
          "shell.execute_reply": "2021-09-26T17:13:16.769348Z",
          "shell.execute_reply.started": "2021-09-26T17:13:06.016399Z"
        },
        "id": "VFg-1frxcagM",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'EEG_Tensorflow_models.Utils'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/home/daniel/Documents/python-gcpds.EEG_Tensorflow_models/Examples/BCI2a/shallowconvnet.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/daniel/Documents/python-gcpds.EEG_Tensorflow_models/Examples/BCI2a/shallowconvnet.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mEEG_Tensorflow_models\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mUtils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mLoadData\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/daniel/Documents/python-gcpds.EEG_Tensorflow_models/Examples/BCI2a/shallowconvnet.ipynb#ch0000003?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mEEG_Tensorflow_models\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mUtils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mCallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m get_callbacks\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/daniel/Documents/python-gcpds.EEG_Tensorflow_models/Examples/BCI2a/shallowconvnet.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mEEG_Tensorflow_models\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mUtils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mTrainingModels\u001b[39;00m \u001b[39mimport\u001b[39;00m get_loss,get_model,get_optimizer,train_model_cv\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'EEG_Tensorflow_models.Utils'"
          ]
        }
      ],
      "source": [
        "from EEG_Tensorflow_models.Utils.LoadData import load_dataset\n",
        "from EEG_Tensorflow_models.Utils.Callbacks import get_callbacks\n",
        "from EEG_Tensorflow_models.Utils.TrainingModels import get_loss,get_model,get_optimizer,train_model_cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-26T17:13:16.77197Z",
          "iopub.status.busy": "2021-09-26T17:13:16.771145Z",
          "iopub.status.idle": "2021-09-26T17:13:16.830566Z",
          "shell.execute_reply": "2021-09-26T17:13:16.829975Z",
          "shell.execute_reply.started": "2021-09-26T17:13:16.77194Z"
        },
        "id": "HGbDskCzfluR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from scipy.signal import resample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yER2E281fKti"
      },
      "source": [
        "# Exp 1: Schirmeister 2017"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-09-26T17:27:36.055302Z",
          "iopub.status.busy": "2021-09-26T17:27:36.054952Z",
          "iopub.status.idle": "2021-09-26T17:30:03.568757Z",
          "shell.execute_reply": "2021-09-26T17:30:03.56567Z",
          "shell.execute_reply.started": "2021-09-26T17:27:36.055268Z"
        },
        "id": "7k3LXi8vcVgI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "opt_args = {'lr': 0.01,'beta_1': 0.9}\n",
        "optimizer = get_optimizer('Adam',opt_args)\n",
        "\n",
        "loss = get_loss('CategoricalCrossentropy')\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "callbacks_names = {'early_stopping_train':'early_stopping','checkpoint_train':'checkpoint',\n",
        "                'Threshold_valid':'Threshold','checkpoint_valid':'checkpoint',\n",
        "                'early_stopping_valid':'early_stopping'}\n",
        "\n",
        "\n",
        "Experiment = 'schirrmeister2017'\n",
        "model_name = 'ShallowConvNet'\n",
        "Version='2018'\n",
        "\n",
        "subjects = np.arange(1,10)\n",
        "Acc = []\n",
        "History = []\n",
        "Subject = []\n",
        "fs_new = 128\n",
        "for sbj in subjects:\n",
        "    print('Subject: {:d} of {:d}'.format(sbj,len(subjects)))\n",
        "\n",
        "    X_train,y_train,X_valid,y_valid,fs = load_dataset(dataset_name=\"BNCI2014001\", subject_id=sbj)\n",
        "    \n",
        "    X_train = resample(X_train,int((X_train.shape[-2]/fs)*fs_new),axis=-2)    \n",
        "    X_valid = resample(X_valid,int((X_valid.shape[-2]/fs)*fs_new),axis=-2)     \n",
        "    \n",
        "\n",
        "    model_args = {'nb_classes':4,'Chans':X_train.shape[1],'Samples':X_train.shape[2],'dropoutRate':0.5,'version':Version}\n",
        "    model = get_model(model_name,model_args)\n",
        "    \n",
        "   \n",
        "\n",
        "    #model_args = {'nb_classes':4,'Chans':X_train.shape[1],'Samples':X_train.shape[2],'dropoutRate':0.5,'version':'2017'}\n",
        "    #model = get_model(model_name,model_args)\n",
        "    \n",
        "    call_args = [{'monitor':'val_accuracy','patience':100,'min_delta':0.001,'mode':'max','verbose':1,'restore_best_weights':False},\n",
        "                {'filepath':'/kaggle/tmp/checkpoint_sbj_'+str(sbj),'save_format':'tf','monitor':'val_accuracy','verbose':1,'save_weights_only':True,'save_best_only':True},\n",
        "                {'threshold':None},\n",
        "                {'filepath':'/kaggle/tmp/checkpoint_2_sbj_'+str(sbj),'save_format':'tf','monitor':'val_accuracy','verbose':1,'save_weights_only':True,'save_best_only':True},\n",
        "                {'monitor':'val_accuracy','patience':None,'min_delta':0.001,'mode':'max','verbose':1,'restore_best_weights':True}]\n",
        "                \n",
        "    callbacks = get_callbacks(callbacks_names,call_args)\n",
        "\n",
        "    cv = train_model_cv(model,optimizer,loss,metrics,callbacks=callbacks)\n",
        "\n",
        "    history = cv.fit_validation(X_train,y_train,X_val=X_valid,y_val=y_valid,batch_size=64,epochs=1000,verbose=1,val_mode=Experiment)\n",
        "    acc = cv.get_accuracy()\n",
        "    print('Subject accuracy: {:f}'.format(acc))\n",
        "    Acc.append(acc)\n",
        "    History.append(History)\n",
        "    Subject.append(sbj)\n",
        "\n",
        "    results = {}\n",
        "    results['subject'] = Subject\n",
        "    results['history'] = History\n",
        "    results['accuracy'] = Acc\n",
        "\n",
        "    with open('Results_BCI2a_'+Experiment+'_'+model_name+Version+'.p','wb') as handle:\n",
        "        pickle.dump(results,handle)\n",
        "    \n",
        "    del cv,callbacks,X_train,y_train,X_valid,y_valid,fs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkmyULdHpERD"
      },
      "source": [
        "#Exp 2: Schirmeister 2017_legal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-24T03:18:13.110208Z",
          "iopub.status.idle": "2021-09-24T03:18:13.110692Z",
          "shell.execute_reply": "2021-09-24T03:18:13.11046Z",
          "shell.execute_reply.started": "2021-09-24T03:18:13.110427Z"
        },
        "id": "KxxJHDIJfjhr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "opt_args = {'lr': 0.01,'beta_1': 0.9}\n",
        "optimizer = get_optimizer('Adam',opt_args)\n",
        "\n",
        "loss = get_loss('CategoricalCrossentropy')\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "callbacks_names = {'early_stopping_train':'early_stopping','checkpoint_train':'checkpoint',\n",
        "                'Threshold_valid':'Threshold','checkpoint_valid':'checkpoint',\n",
        "                'early_stopping_valid':'early_stopping'}\n",
        "\n",
        "\n",
        "Experiment = 'schirrmeister2017_legal'\n",
        "model_name = 'ShallowConvNet'\n",
        "Version='2018'\n",
        "\n",
        "subjects = np.arange(1,10)\n",
        "Acc = []\n",
        "History = []\n",
        "Subject = []\n",
        "for sbj in subjects:\n",
        "    print('Subject: {:d} of {:d}'.format(sbj,len(subjects)))\n",
        "\n",
        "    X_train,y_train,X_valid,y_valid,fs = load_dataset(dataset_name=\"BNCI2014001\", subject_id=sbj)\n",
        "    fs_new = 128\n",
        "    X_train = resample(X_train,int((X_train.shape[-2]/fs)*fs_new),axis=-2)    \n",
        "    X_valid = resample(X_valid,int((X_valid.shape[-2]/fs)*fs_new),axis=-2)    \n",
        "    model_args = {'nb_classes':4,'Chans':X_train.shape[1],'Samples':X_train.shape[2],'dropoutRate':0.5,'version':Version}\n",
        "    model = get_model(model_name,model_args)\n",
        "\n",
        "\n",
        "    call_args = [{'monitor':'val_accuracy','patience':100,'min_delta':0.001,'mode':'max','verbose':1,'restore_best_weights':False},\n",
        "                {'filepath':'/kaggle/tmp/checkpoint_sbj_'+str(sbj),'save_format':'tf','monitor':'val_accuracy','verbose':1,'save_weights_only':True,'save_best_only':True},\n",
        "                {'threshold':None},\n",
        "                {'filepath':'/kaggle/tmp/checkpoint_2_sbj_'+str(sbj),'save_format':'tf','monitor':'val_accuracy','verbose':1,'save_weights_only':True,'save_best_only':True},\n",
        "                {'monitor':'val_accuracy','patience':None,'min_delta':0.001,'mode':'max','verbose':1,'restore_best_weights':True}]\n",
        "                \n",
        "    callbacks = get_callbacks(callbacks_names,call_args)\n",
        "\n",
        "    cv = train_model_cv(model,optimizer,loss,metrics,callbacks=callbacks)\n",
        "\n",
        "    history = cv.fit_validation(X_train,y_train,X_val=X_valid,y_val=y_valid,batch_size=64,epochs=1000,verbose=1,val_mode=Experiment)\n",
        "    acc = cv.get_accuracy()\n",
        "    print('Subject accuracy: {:f}'.format(acc))\n",
        "    Acc.append(acc)\n",
        "    History.append(History)\n",
        "    Subject.append(sbj)\n",
        "\n",
        "    results = {}\n",
        "    results['subject'] = Subject\n",
        "    results['history'] = History\n",
        "    results['accuracy'] = Acc\n",
        "\n",
        "    with open('Results_BCI2a_'+Experiment+'_'+model_name+Version+'.p','wb') as handle:\n",
        "        pickle.dump(results,handle)\n",
        "    \n",
        "    del cv,callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc57RFoppu6I"
      },
      "source": [
        "# Exp 3: Schirmeister 2021"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-24T03:18:13.112271Z",
          "iopub.status.idle": "2021-09-24T03:18:13.112757Z",
          "shell.execute_reply": "2021-09-24T03:18:13.112522Z",
          "shell.execute_reply.started": "2021-09-24T03:18:13.112497Z"
        },
        "id": "e3zhvmwHpyJ2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "opt_args = {'lr': 0.01,'beta_1': 0.9}\n",
        "optimizer = get_optimizer('Adam',opt_args)\n",
        "\n",
        "loss = get_loss('CategoricalCrossentropy')\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "callbacks_names = {'checkpoint_valid':'checkpoint',\n",
        "                   'early_stopping_valid':'early_stopping'}\n",
        "\n",
        "\n",
        "Experiment = 'schirrmeister2021'\n",
        "model_name = 'ShallowConvNet'\n",
        "Version='2018'\n",
        "\n",
        "subjects = np.arange(1,10)\n",
        "Acc = []\n",
        "History = []\n",
        "Subject = []\n",
        "for sbj in subjects:\n",
        "    print('Subject: {:d} of {:d}'.format(sbj,len(subjects)))\n",
        "\n",
        "    X_train,y_train,X_valid,y_valid,fs = load_dataset(dataset_name=\"BNCI2014001\", subject_id=sbj)\n",
        "    fs_new = 128\n",
        "    X_train = resample(X_train,int((X_train.shape[-2]/fs)*fs_new),axis=-2)    \n",
        "    X_valid = resample(X_valid,int((X_valid.shape[-2]/fs)*fs_new),axis=-2)    \n",
        "    model_args = {'nb_classes':4,'Chans':X_train.shape[1],'Samples':X_train.shape[2],'dropoutRate':0.5,'version':Version}\n",
        "    model = get_model(model_name,model_args)\n",
        "    \n",
        "    \n",
        "\n",
        "    call_args = [\n",
        "            {'filepath':'/kaggle/tmp/checkpoint_'+str(sbj),\n",
        "            'save_format':'tf',\n",
        "            'monitor':'val_accuracy',\n",
        "            'verbose':1,\n",
        "            'save_weights_only':True,\n",
        "            'save_best_only':True},\n",
        "            {'monitor':'val_accuracy',\n",
        "            'patience':100,\n",
        "            'min_delta':0.001,\n",
        "            'mode':'max',\n",
        "            'verbose':1,\n",
        "            'restore_best_weights':True}]\n",
        "                \n",
        "    callbacks = get_callbacks(callbacks_names,call_args)\n",
        "\n",
        "    cv = train_model_cv(model,optimizer,loss,metrics,callbacks=callbacks)\n",
        "\n",
        "    history = cv.fit_validation(X_train,y_train,X_val=X_valid,y_val=y_valid,batch_size=64,epochs=1000,verbose=1,val_mode=Experiment)\n",
        "    acc = cv.get_accuracy()\n",
        "    print('Subject accuracy: {:f}'.format(acc))\n",
        "    Acc.append(acc)\n",
        "    History.append(History)\n",
        "    Subject.append(sbj)\n",
        "\n",
        "    results = {}\n",
        "    results['subject'] = Subject\n",
        "    results['history'] = History\n",
        "    results['accuracy'] = Acc\n",
        "\n",
        "    with open('Results_BCI2a_'+Experiment+'_'+model_name+Version+'.p','wb') as handle:\n",
        "        pickle.dump(results,handle)\n",
        "    \n",
        "    del cv,callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AYFMYo_qWks"
      },
      "source": [
        "# Exp 4: 4-fold CV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-24T03:18:13.114398Z",
          "iopub.status.idle": "2021-09-24T03:18:13.114881Z",
          "shell.execute_reply": "2021-09-24T03:18:13.114657Z",
          "shell.execute_reply.started": "2021-09-24T03:18:13.114632Z"
        },
        "id": "FPWVi22jqf-U",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "opt_args = {'lr': 0.01,'beta_1': 0.9}\n",
        "optimizer = get_optimizer('Adam',opt_args)\n",
        "\n",
        "loss = get_loss('CategoricalCrossentropy')\n",
        "\n",
        "metrics = ['accuracy']\n",
        "\n",
        "callbacks_names = {'checkpoint_train1':'checkpoint','checkpoint_train2':'checkpoint','checkpoint_train3':'checkpoint','checkpoint_train4':'checkpoint'}\n",
        "\n",
        "\n",
        "Experiment = 'lawhern2018'\n",
        "model_name = 'ShallowConvNet'\n",
        "Version='2018'\n",
        "\n",
        "fs_new = 128\n",
        "\n",
        "\n",
        "subjects = np.arange(1,10)\n",
        "Acc = []\n",
        "History = []\n",
        "Subject = []\n",
        "for sbj in subjects:\n",
        "    print('Subject: {:d} of {:d}'.format(sbj,len(subjects)))\n",
        "\n",
        "    X_train,y_train,X_valid,y_valid,fs = load_dataset(dataset_name=\"BNCI2014001\", subject_id=sbj)\n",
        "    fs_new = 128\n",
        "    X_train = resample(X_train,int((X_train.shape[-2]/fs)*fs_new),axis=-2)    \n",
        "    X_valid = resample(X_valid,int((X_valid.shape[-2]/fs)*fs_new),axis=-2)    \n",
        "    model_args = {'nb_classes':4,'Chans':X_train.shape[1],'Samples':X_train.shape[2],'dropoutRate':0.5,'version':Version}\n",
        "    model = get_model(model_name,model_args)\n",
        "\n",
        "    call_args = [\n",
        "            \n",
        "            {'filepath':'/kaggle/tmp/checkpoint1_'+str(sbj),\n",
        "            'save_format':'tf',\n",
        "            'monitor':'val_accuracy',\n",
        "            'verbose':1,\n",
        "            'save_weights_only':True,\n",
        "            'save_best_only':True},\n",
        "             {'filepath':'/kaggle/tmp/checkpoint2_'+str(sbj),\n",
        "            'save_format':'tf',\n",
        "            'monitor':'val_accuracy',\n",
        "            'verbose':1,\n",
        "            'save_weights_only':True,\n",
        "            'save_best_only':True},\n",
        "             {'filepath':'/kaggle/tmp/checkpoint3_'+str(sbj),\n",
        "            'save_format':'tf',\n",
        "            'monitor':'val_accuracy',\n",
        "            'verbose':1,\n",
        "            'save_weights_only':True,\n",
        "            'save_best_only':True},\n",
        "             {'filepath':'/kaggle/tmp/checkpoint4_'+str(sbj),\n",
        "            'save_format':'tf',\n",
        "            'monitor':'val_accuracy',\n",
        "            'verbose':1,\n",
        "            'save_weights_only':True,\n",
        "            'save_best_only':True}]\n",
        "                \n",
        "    callbacks = get_callbacks(callbacks_names,call_args)\n",
        "\n",
        "    cv = train_model_cv(model,optimizer,loss,metrics,callbacks=callbacks)\n",
        "\n",
        "    history = cv.fit_validation(X_train,y_train,X_val=X_valid,y_val=y_valid,batch_size=64,epochs=1000,verbose=1,val_mode=Experiment)\n",
        "    acc = cv.get_accuracy()\n",
        "    print('Subject accuracy: {:f}'.format(acc))\n",
        "    Acc.append(acc)\n",
        "    History.append(History)\n",
        "    Subject.append(sbj)\n",
        "\n",
        "    results = {}\n",
        "    results['subject'] = Subject\n",
        "    results['history'] = History\n",
        "    results['accuracy'] = Acc\n",
        "\n",
        "    with open('Results_BCI2a_'+Experiment+'_'+model_name+Version+'.p','wb') as handle:\n",
        "        pickle.dump(results,handle)\n",
        "    \n",
        "    del cv,callbacks"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "shallowconvnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
